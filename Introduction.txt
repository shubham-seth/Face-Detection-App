<p>
This app was developed by Shubham Seth and Yash Sanjeev. The app is a basic face detector and is useful to compare the different object detection models out there. But before you begin <br>
playing around with the app, we would like to give you a small background and origin of the various object detection algorithms out there. There are a lot of <br>
places we can begin our tale, but we find that it's appropriate to begin it in 2014, with the development of RCNN. <br>
</p>

<h2> RCNN - 2014 </h2>
<p>
Regional Convolutional Neural Network, or RCNN for short, in our opinion were the founding block of Object Detection algorithms. The idea was instead of <br>
running the CNN one by one over each square in the image and identyfying whether it contains a foreground object or background, we simply run the classifier <br>
over regions with a higher probability of having objects in them. This was achieved using selective search, an algorithm which detected blob like features in <br>
images. You can read more about it <a href="http://www.cs.cornell.edu/courses/cs7670/2014sp/slides/VisionSeminar14.pdf">here</a>. 
</p>

<p>
Once the Selective Search returned around 2000 region proposals, we individually run a CNN classifier over all of them <br>
and try to extract the various features. In the end, an SVM is used to classify between the different objects or whether the region <br>
proposed is just background. A linear regression was also run on the bounding boxes in order to obtain a tighter bounding box.<br>
</p> 

<p>
Thus the pipeline looked something like:-
<ol>
<li> Pass the image through a selective search algorithm. This results approximately 2000 region proposals </li>
<li> Take each region proposal and pass a CNN over it. Extract the features from this network's final fully connected layer </li>
<li> Pass each feature through an SVM and classify whether its background or a foreground object of a certain type </li>
<li> If an object is detected, pass the features through a linear regressor, and obtain a tighter bounding box over the object </li>
</ol>
</p>

<p>
However, the RCNN model had a few glaring problems:-
<ul>
<li> It was pretty slow as it requried to run a CNN(AlexNet) over every region proposal generated by the selective search algorithm. </li> 
<li> It has to train three different models separately - the CNN to generate image features, the classifier that predicts the class, <br>
and the regression model to tighten the bounding boxes. This makes the pipeline extremely hard to train. </li>
</ul>
</p>

<h2> Fast RCNN - 2015 </h2>
<p>
Fast RCNN was based on a couple of genius insights by Ross Girschick, the author of the original RCNN paper. <br>
His first insight was the idea of passing the entire image through a CNN and sharing this calculations over the <br>
various regions generated by selective search. What this means is that the image region generated by selective <br>
search can be mapped to a region in the CNN features generated. This region is then passed through a RoI pool, <br>
whuch converts CNN features of each region proposal to the same size, usually using Max Pooling. Once they are <br>
of the same size, its easy to generate features for all of them and generate outputs in a single pass. Thus, <br>
instead of 2000 passes, all it took was a single pass!
</p>

<p>
His second insight was that instead of training three different models like he did in RCNN, it would be more practical <br>
and easier to train one model, combining the CNN, SVM and bounding box regressor into one, thus making the process way less tedious.
</p>

<p>
However, despite being significantly faster than its ancestor, it still had a bottleneck while running. That <br>
was the selective search algorithm. It took time to generate 2000 region proposals, and this slowed down the entire process.
</p>

<h2> Faster RCNN - 2016 </h2>
<p>
In this 2016 paper, the unsupervised method of generating Region of Interests was thrown out of the window, <br>
and was replaced by supervised learning.
</p>

<p>
How exactly was this achieved? Well, a sliding window was passed over the feature map and each window was passed through <br>
a Fully Convolutional Network, and it generated scores of whether the window contained an object and the coordinates of the <br>
bounding box within it. Each of the windows is called an anchor. Then, each region proposed which is likely to be an object <br>
is passed into the Fast R-CNN to generate a classification and tightened bounding boxes. <br>
</p>

<p>
This creative approach makes it possible for the region proposals to be generated in no time. We only wish the authors were <br>
as creative as the approach while naming the model. 
</p>

<h2> Mask RCNN - 2017 </h2>
<p>
While the above algorithms work to generate rectangular bounding boxes, this model takes it a step further, by generating <br>
pixel level segmentation of the object. How does it do it?
</p>

<p>
Mask R-CNN does this by adding a branch to Faster R-CNN that outputs a binary mask that says whether or not a given pixel is <br>
part of an object. The branch, is just a Fully Convolutional Network on top of a CNN based feature map. It takes the CNN feature <br>
map as input, and generates a binary mask as the output.
</p>

<p>
Mask RCNN however did also change one small thing. Instead of using RoI pool, it switched over to RoI align, which is a more <br>
accurate version of the former, and while it wasn't necessary during generation of bounding boxes, it became needed during <br>
the generation of pixel level segmentation. In short, it covers for the ignored approximation of bounding box from the feature <br>
map in FasterRCNN by using bilinear interpolation.
</p>

<h2> YOLO v3 - 2018 </h2>
<p>
YOLO takes a completely different approach to object detection. It first splits the grid into 13 x 13 cells, and then a <br>
convolutional network is passed over each cell. Each cell generates 5 bounding boxes. From the bounding box, YOLO generates <br>
a confidence score and a class. If the confidence score is above a certain level, the class is predicted. The results are obtained <br>
after removing low confidence outputs and overlapping boxes. The entire pass happens in one go and since it's just a simple <br>
convolutional network, its pretty fast. In-fact, it is used for real time detection! <br>
</p>
